<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yoursite.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="光纤通道实现的NVMe(FC-NVMe标准实现)是一项技术规范，旨在实现在主机和光纤通道网络结构上的目标存储子系统上传输NVMe的消息命令和信息。  光纤通道是面向NVMe over Fabrics(NVMe-oF)的Fabric传输选项，由NVM Express Inc.(一家拥有100多家成员技术公司的非营利组织)开发的规范。其他NVMe传输选项包括以太网和InfiniBand上的远程直接内存">
<meta property="og:type" content="article">
<meta property="og:title" content="十五、基于FC的NVMe或FC-NVMe标准">
<meta property="og:url" content="http://yoursite.com/2020/10/21/store/NVMe/%E5%8D%81%E4%BA%94%E3%80%81%E5%9F%BA%E4%BA%8EFC%E7%9A%84NVMe%E6%88%96FC-NVMe%E6%A0%87%E5%87%86/index.html">
<meta property="og:site_name" content="摘星">
<meta property="og:description" content="光纤通道实现的NVMe(FC-NVMe标准实现)是一项技术规范，旨在实现在主机和光纤通道网络结构上的目标存储子系统上传输NVMe的消息命令和信息。  光纤通道是面向NVMe over Fabrics(NVMe-oF)的Fabric传输选项，由NVM Express Inc.(一家拥有100多家成员技术公司的非营利组织)开发的规范。其他NVMe传输选项包括以太网和InfiniBand上的远程直接内存">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://yoursite.com/pics/image-20210418144801040.png">
<meta property="og:image" content="http://yoursite.com/pics/image-20210418144920587.png">
<meta property="og:image" content="http://yoursite.com/pics/image-20210418145910351.png">
<meta property="og:image" content="http://yoursite.com/pics/image-20210418150005187.png">
<meta property="og:image" content="http://yoursite.com/pics/image-20210418150102852.png">
<meta property="og:image" content="http://yoursite.com/pics/image-20210418150248531.png">
<meta property="og:image" content="http://yoursite.com/pics/image-20210418150744705.png">
<meta property="article:published_time" content="2020-10-21T15:58:13.000Z">
<meta property="article:modified_time" content="2020-10-21T15:58:13.000Z">
<meta property="article:author" content="摘星">
<meta property="article:tag" content="Store">
<meta property="article:tag" content="NVMe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/pics/image-20210418144801040.png">

<link rel="canonical" href="http://yoursite.com/2020/10/21/store/NVMe/%E5%8D%81%E4%BA%94%E3%80%81%E5%9F%BA%E4%BA%8EFC%E7%9A%84NVMe%E6%88%96FC-NVMe%E6%A0%87%E5%87%86/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>十五、基于FC的NVMe或FC-NVMe标准 | 摘星</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">摘星</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/10/21/store/NVMe/%E5%8D%81%E4%BA%94%E3%80%81%E5%9F%BA%E4%BA%8EFC%E7%9A%84NVMe%E6%88%96FC-NVMe%E6%A0%87%E5%87%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="摘星">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="摘星">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          十五、基于FC的NVMe或FC-NVMe标准
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-10-21 23:58:13" itemprop="dateCreated datePublished" datetime="2020-10-21T23:58:13+08:00">2020-10-21</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Store/" itemprop="url" rel="index"><span itemprop="name">Store</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>光纤通道实现的NVMe(FC-NVMe标准实现)是一项技术规范，旨在实现在主机和光纤通道网络结构上的目标存储子系统上传输NVMe的消息命令和信息。 </p>
<p>光纤通道是面向NVMe over Fabrics(NVMe-oF)的Fabric传输选项，由NVM Express Inc.(一家拥有100多家成员技术公司的非营利组织)开发的规范。其他NVMe传输选项包括以太网和InfiniBand上的远程直接内存访问(RDMA)。NVM Express Inc.于2016年6月5日发布了1.0版NVMe-oF。 </p>
<p>国际信息技术标准委员会(INCITS)的T11委员会定义了一种帧格式和映射协议，将NVMe-oF应用到光纤通道。T11委员会于2017年8月完成了FC-NVMe标准的第一版，并将其提交给INCITS出版。 </p>
<h1 id="FC-NVMe如何工作"><a href="#FC-NVMe如何工作" class="headerlink" title="FC NVMe如何工作"></a>FC NVMe如何工作</h1><p>FC协议(FCP)允许上层传输协议，如NVMe，小型计算机系统接口(SCSI)和IBM专有光纤连接(FICON)的映射，以实现主机和外围目标存储设备或系统之间的数据和命令传输。 </p>
<p>与SCSI和FICON相比，NVMe具有简化的寄存器接口和命令集，减少了输入/输出(I/O)堆栈的CPU开销，降低了延迟并提高了性能。NVM Express Inc.开发了适用于快速介质的NVMe，包括固态硬盘(SSD)和其他基于内存的</p>
<p>技术。相比之下，SCSI命令集是在较慢的硬盘驱动器(HDD)和磁带作为主要存储介质的时候设计的，而FICON则是为连接大型计算机和存储设备而设计的。 </p>
<p><img src="/pics/image-20210418144801040.png" alt="image-20210418144801040"></p>
<p>NVMe传输是一种抽象协议层，旨在提供可靠的NVMe命令和数据传输。 </p>
<p>FC-NVMe将NVMe命令集简化为基本的FCP指令。由于光纤通道专为存储流量而设计，因此系统中内置了诸如发现，管理和设备端到端验证等功能。 </p>
<p>NVMe-oF(包括通过光纤通道的NVMe)和NVMe之间的主要区别是传输命令的机制。NVMe通过外围组件互连Express(PCIe)接口协议将请求和响应映射到主机中的共享内存。NVMe-oF使用基于消息的模型通过网络在主机和目标存储设备之间发送请求和响应。 </p>
<p>NVMe-oF替代PCIe来扩展NVMe主机和NVMe存储子系统进行通信的距离。与使用本地主机的PCIe 总线的NVMe存储设备的延迟相比，NVMe-oF的最初设计目标是在通过合适的网络结构连接的NVMe主机和NVMe存储目标之间添加不超过10 微秒的延迟。 </p>
<p>在大规模基于块闪存的存储环境最有可能采用NVMe over FC。FC-NVMe光纤通道提供的NVMe-oF结构、可预测性和可靠性特性等与给SCSI提供的相同，另外，NVMe-oF流量和传统的基于SCSI的流量可以在同一FC结构上同时运行。 </p>
<p><img src="/pics/image-20210418144920587.png" alt="image-20210418144920587"></p>
<p>基于FC标准的NVMe定义了FC-NVMe协议层。NVMe over Fabrics规范定义了NVMe-oF协议层。NVMe规范定义了NVMe主机软件和NVM子系统协议层。 </p>
<p>要求必须支持基于光纤通道的NVMe才能发挥潜在优势的基础架构组件，包括存储操作系统(OS)和网络适配器卡。FC存储系统供应商必须让其产品符合FC-NVMe的要求。目前支持FC-NVMe的主机总线适配器(HBA)的供应商包括Broadcom和Cavium。Broadcom和思科是主要的FC交换机供应商。 </p>
<h1 id="FC-NVMe的优点和缺点"><a href="#FC-NVMe的优点和缺点" class="headerlink" title="FC-NVMe的优点和缺点"></a>FC-NVMe的优点和缺点</h1><p>与HDD或串行高级技术的SCSI命令集(SATA或串行SCSI SAS SSD)进行数据传输相比，FC-NVMe具有更高的性能，更低的延迟。基于NVMe的SSD的一个缺点可能是成本较高，但NVMe SSD的价格有望与某些类型的传统SSD达成平衡。 </p>
<p>将FC-NVMe与基于以太网或InfiniBand的NVMe-oF替代方案进行比较，如果考虑网络技术的优缺点，光纤通道结构以其无损数据传输，可预测和一致的性能以及可靠性而闻名。大型企业倾向于将FC存储用于关键任务工作负载。但光纤通道需要特殊的设备和存储网络专业知识才能运行，并且可能比基于以太网的替代方案更昂贵。 </p>
<p>基于以太网的NVMe存储产品往往比基于FC-NVMe的选件更丰富。大多数存储创业公司都专注于基于以太网的NVMe，并且有时采用专有技术来更快地将其产品推向市场。 </p>
<p>基于InfiniBand的NVMe倾向于吸引需要极高带宽和低延迟的高性能计算工作负载。InfiniBand网络通常用于后端存储系统内的通信，而不是主机到存储器的通信。与FC一样，InfiniBand是一个需要特殊硬件的无损网络，它具有诸如流量和拥塞控制以及服务质量(QoS)等优点。但与FC不同的是，InfiniBand和以太网缺少发现服务自动将节点添加到结构中。 </p>
<p>NVMe-oF规范支持RDMA(但并非必需)，映射方式包括用于以太网和InfiniBand的融合以太网(RoCE)上的RDMA和用于互联网的广域RDMA协议(iWARP)。NVMe Express组织还计划支持传输控制协议(TCP)的传输选项 </p>
<p>Brocade最近发表了对NVMe over Fabric理解和观点，认为FC Fabric相比以太网具有很多优势，并且FC聚焦数据中心数据传输和交换，具有更好的网络安全性。 </p>
<p>目前，基于SCSI的全闪存和混合阵列正成为数据中心的主流，但与此同时，一种为固态PCIe模块专门构建的非易失性存储器(NVMe)标准已经成为服务</p>
<p>器连接Flash的一个新的高性能接口。NVMe通过低延迟和增强队列机制提供了更好的随机和连续性能，并增加了传统协议(如SAS)应用程序的并行性。 </p>
<p>为了支持数据中心的网络存储，通过NVMe over Fabric实现NVMe标准在PCIe总线上的扩展，以此来挑战SCSI在SAN中的统治地位。NV Me over Fabric支持把NVMe映射到多个Fabrics传输选项，主要包括FC、InfiniBand、RoCE v2和iWARP。 </p>
<p>随着NVMe的发展和NVMe over Fabric技术商品化，在SAN市场，将NVMe定位为SCSI的替代方案，这也为Flash模块供应商打开一扇门来应对这个新的市场。自然地，存储市场的新来者试图吹捧他们的技术有优势，然而，新技术的缺点可能没有受到太多关注。通过作者的分析，希望大家能对NVMe和NVMe over Fabrics技术有个综合全面的认识。 </p>
<h2 id="FC不但可以作为NVMe的Fabrics且更有优势"><a href="#FC不但可以作为NVMe的Fabrics且更有优势" class="headerlink" title="FC不但可以作为NVMe的Fabrics且更有优势"></a>FC不但可以作为NVMe的Fabrics且更有优势</h2><p>FC实际上是支持NVMe的一种fabrics选择。NVMe over fabric白皮书上概述了对NVMe支持的两种类型的fabrics，一个是RDMA和一个是使用FC。尽管一些竞争者会声称光纤通道不是合法的NVMe Fabric，但是NVM Express白皮书例证说明了这个问题。 </p>
<p>同样，白皮书明确列出了光纤通道作为一个NVMe over Fabrics选择，也描述了理想的Fabrics需要具备可靠的、以Credit为基础的流量控制和交付机制。然而，基于Credit的流程控制机制是FC、InfiniBand和PCIe传输原生能力。基于Credit流控制不是以太网/ IP网络的一部分，所以，相比iWARP或RoCE的以太网Fabrics，FC实际上是NVMe更好的Fabrics选择。 </p>
<h2 id="RDMA也不是NVMe-Fabric的关键"><a href="#RDMA也不是NVMe-Fabric的关键" class="headerlink" title="RDMA也不是NVMe Fabric的关键"></a>RDMA也不是NVMe Fabric的关键</h2><p>RDMA提倡者一般声称RDMA对设计好NVMe Fabric很重要。但在NVMe的白皮书中并没有把RDMA列为“理想”NVMe over Fabric的重要属性，也就是说RDMA除了只是一种实现NVMe Fabric的方法外，没有什么特别的。在博科看来，InfiniBand社区在RDMA有较大投入且与PCIe社区合作紧密，但是NVMe和NVMe over Fabric本身并不依赖于RDMA。 </p>
<h2 id="SCSI也不是唯一的FC-Native协议"><a href="#SCSI也不是唯一的FC-Native协议" class="headerlink" title="SCSI也不是唯一的FC Native协议"></a>SCSI也不是唯一的FC Native协议</h2><p>RDMA倡导者通常将NVMe over以太网/IP和FC的延迟时间进行比较(这就像比较把IP和以太网比较一样)，由于NVMe是上层协议，光纤通道是链路层协议。完整的比较应该是把NVMe over以太网和SCSI over FC进行比较，如果描述正确的话，这才是一个有效的比较。现在，作为光纤通道专家也意识到一个问题，由于FC上承载SCSI叫光纤通道协议(FCP)，所以不止一个新手错误地认为所有的FC通信都必须是FCP。但事实上FCP与FC不一样，FCP仅仅是一种FC-4(上层)协议，类似于FICON(大型机存储协议)，可以通过FC传输。 </p>
<p>常常产生的一个误解是NVMe首先被翻译成底层SCSI(FCP)之后才运行在FC上。这种误解很有可能是由同样的白皮书引起的，它告诉我们理想的NVMe传输应该允许客户端“直接发送和接收本地NVMe命令，无需使用诸SCSI如此类的转换层”。这句话本身这是有道理的，因为NVMe是延迟优化的，而转换层却会引入延迟。 </p>
<p>实际上FC本身就可以运输NVMe，无需翻译和转化。NVMe over FC定义了一个新的上层FC-NVMe流量类型，它识别了特定于NVMe的帧。 </p>
<p>FC-NVMe标准组织认为在FC上同时支持NVMe和SCSI会具有更大价值。FC-NVMe标准规定了NVMe over FC使用与FCP相同IO框架类型。FC作为多协议结构的长期使用和应用表明FC SAN同时支持SCSI和NVMe是非常可靠的。 </p>
<h2 id="如何看待SCSI到NVMe转换层对NVMe产生的影响？"><a href="#如何看待SCSI到NVMe转换层对NVMe产生的影响？" class="headerlink" title="如何看待SCSI到NVMe转换层对NVMe产生的影响？"></a>如何看待SCSI到NVMe转换层对NVMe产生的影响？</h2><p>NVMe fabric聚焦于最低延迟，NVMe over fabric的白皮书说明传输的一个理想方式是不需要翻译层，如果存在SCSI到NVMe转换就是次优的传输方式。在编写应用程序时，如果能直接使用NVMe，不但有效避免翻译步骤，还将避免了每IO引入的时钟周期。FC不需要转换翻译且支持Native NVMe。 </p>
<p>与此同时，NVMe社区也意识到SCSI应用程序部署时，上层应用程序适配、兼容和SCSI到NVMe转换层的重要性。许多NVMe的潜在用户无法重新设计他们运行的应用程序，但希望能选择搬到NVMe基础设施之上，不依赖于它们的应用程序供应商重新设计。从这个角度来看，有一个转化翻译层作为一种选择对NVMe的采用和普及实际上是有益的。 </p>
<p>值得庆幸的是，目前业界主流的HBA厂商都提供了从SCSI到 NVMe转换翻译的驱动程序，同时也提供Native NVMe能力支持原生支持NVMe over Fabric应用程序。 </p>
<h2 id="FC能否实现零拷贝-Zero-Copy-功能？"><a href="#FC能否实现零拷贝-Zero-Copy-功能？" class="headerlink" title="FC能否实现零拷贝(Zero Copy)功能？"></a>FC能否实现零拷贝(Zero Copy)功能？</h2><p>IP堆栈当时被开发时，主要设计用于处理许多上层协议和许多层2网络，从令牌环到电话线，清晰的网络层划分对于互操作性有很好的意义，为了达到这个目的最好的选择是使用中间缓冲，使缓冲区复制公共数据。 </p>
<p>在20世纪80年代早期，提供单副本复制(Single-Copy)也算是一个好的网络协议栈，网络接口卡(NIC)接收帧后，通过DMA技术将它们写到与网络堆栈相关联的DRAM缓冲区中，然后堆栈会决定哪个应用应该接受、继续处理帧数据，并把数据复制到应用对应的DRAM缓存区中。 </p>
<p><img src="/pics/image-20210418145910351.png" alt="image-20210418145910351"></p>
<p>在20世纪80年代中期，随着FC的生产，一切发生了变化。FC主要特点就是速度，所以为了达到优化的目前，FC允许芯片技术更复杂，FC/SCSI堆栈的层数更少，也放开了IP堆栈所面临的向后兼容性的限制。因此，FC实现一个适配器、驱动模型的堆栈架构，从而消除单一副本(Single-Copy)。 </p>
<p><img src="/pics/image-20210418150005187.png" alt="image-20210418150005187"></p>
<p>事实也确实如此，当应用程序请求存储IO时，应用程序以“逻辑地址范围”的形式指定一个缓冲区地址，然后将其转换为DMA的物理地址范围实现DMA传输。有时，一个逻辑范围将映射到多个物理块，因此HBA采用Scatter-Gather List (SGL)完成数据传输和保存。FC通过提供零拷贝(Zero-Copy)技术，支持DMA数据传输。RDMA通过从本地服务器传递Scatter-Gather List到远程服务器有效地将本地内存与远程服务器共享，使远程服务器可以直接读取或写入本地服务器的内存。 </p>
<h2 id="IP上的零拷贝-Zero-Copy-也不需要RDMA"><a href="#IP上的零拷贝-Zero-Copy-也不需要RDMA" class="headerlink" title="IP上的零拷贝(Zero-Copy)也不需要RDMA"></a>IP上的零拷贝(Zero-Copy)也不需要RDMA</h2><p>由于RDMA越来越流行，因此在2007年将其扩展了到Internet Wide Area网络，从而形成RDMA协议(iWARP)标准。iWARP是建立在TCP之上的，传输协议使用确认和重传机制。TCP还采用一个“窗口”算法以避免传输超过了发送方和接收方之间的网络容量。 </p>
<p>在Internet Engineering Task Force (IETF) Requests For Comment (RFCs 5040–5044)中，前一个RFC 5040中描述了RDMA如何使用Direct Data Placement (DDP)协议来实现FC和InfiniBand的零拷贝(Zero-Copy)效率，后一个RFC 5044标记了TCP中PDU对齐规范，有效地禁用了TCP 的“合并”行为，使得NIC更容易地处理接收的数据，提供DDP的硬件支持。 </p>
<p><img src="/pics/image-20210418150102852.png" alt="image-20210418150102852"></p>
<p>前面提到的RFCs为零拷贝(Zero-Copy)效率提供了基础，但是传统的NICs没有TCP处理功能。软件实现虽然提供了互操作性，但无法满足RDMA性能要求。为此，新的称为TCP Offload Engines (TOEs)的NICs卡就产生了，然而早期的TOEs都不适合iWARP，只有基于硬件实现DDP能力的RDMA使能TOEs才能提供类似FC一样的零拷贝(Zero-Copy)效果。 </p>
<p>2009年前后，随着当时InfiniBand市场的低迷，NVMe获得了越来越多的关注，IETF的Transparent Interconnection of Lots of Links (TRILL) 和IEEE的 Data Center Bridging (DCB)获得发展动力并以太网成为无损的Fabric。其中TRILL是指除IEEE的生成树协议支持以外的任何以太网拓扑结构；DCB采用基于优先级的流量控制、增强的传输选择和数据中心桥接交换技术。 </p>
<p>InfiniBand行业协会(IBTA)看到了一个机会，在新的技术领域利用其在RDMA方面的专业知识，因此，他们开发了RDMA over Converged Ethernet (RoCE)规范(Converged Ethernet就是早期的DCB)。就像iWARP需要专门的TOEs来实现零拷贝(Zero-Copy)效率一样，RoCE依赖于RDMA-enabled NICs (RNICs)实现这一能力。IBTA认为RoCE的性能比iWARP更高，并指出了TCP (iWARP)不是低延迟通信的理想协议。 </p>
<p>因为以太网不提供类似TCP的可靠传输能力，RoCE标准是在更高层的协议堆栈中实现可靠性功能。在RoCE发布的时候，对IPv4地址有相关约束，对TRILL的2层以太网网络扩展能力也有很高要求。IBTA显然认为RoCE应该拥有交付大规模高性能RDMA所需的一切能力。 </p>
<h2 id="可路由的RoCE-v2才是更好的RoCE"><a href="#可路由的RoCE-v2才是更好的RoCE" class="headerlink" title="可路由的RoCE v2才是更好的RoCE"></a>可路由的RoCE v2才是更好的RoCE</h2><p>Hyper-Scale和软件定义的网络推崇者促使IBTA创建RoCE v2(有时会被称为“可路由的RoCE”)，意在取代RoCE。不同于基于TCP的iWARP， RoCE v2运行在UDP之上没有缓慢启动的节流行为。当然，采用UDP意味着RoCEv2帧不兼容RoCEv1帧(尽管支持RoCEv2的RDMA-enable的NICs通常可以配置为使用RoCE v1格式)。因为基于UDP的 RoCEv2缺乏类似TCP的显式拥塞通知能力，所以IBTA指出通过支持IETF的ECN实现在UDP之上传输层的流控制。 </p>
<h2 id="网络化的RDMA经历了一个艰难的阶段"><a href="#网络化的RDMA经历了一个艰难的阶段" class="headerlink" title="网络化的RDMA经历了一个艰难的阶段"></a>网络化的RDMA经历了一个艰难的阶段</h2><p>大约在2009年，NVMe获得了越来越多的关注，而当时InfiniBand市场的steam正处于低谷，IETF的大量链路透明互连(TRILL)和IEEE的数据中心桥接(DCB)作为让以太网成为无损结构的一种方式也获得了越来越多的关注。(创建TRILL是为了支持IEEE的生成树协议不支持的任何到任何以太网拓扑。DCB集成了基于优先级的流量控制、增强的传输选择和数据中心桥接交换。 </p>
<p>InfiniBand Trade Association (IBTA)看到了一个机会，可以在一个新的技术领域改变自己在RDMA方面的专长，因此他们通过聚合以太网(RoCE，发音为“rocky”)规范(“聚合以太网”是DCB的早期术语)开发了RDMA。正如iWARP需要特殊的TOE来提供零拷贝效率一样，RoCE依赖于rdma支持的NICs (RNICs)来实现这种性能。 </p>
<p>IBTA的RoCE宣称比iWARP更高的性能,指出TCP、iWARP的基础并不是理想的低延迟通信协议，当发起一个连接或者连接已经闲置了一段时间，在一定程度上TCP存在“慢启动”行为。由于以太网不提供TCP的可靠传输能力，RoCE标准在堆栈的更高层实现了这种能力。在RoCE发布的时候，IPv4地址约束是最重要的，TRILL承诺从根本上扩展第二层以太网网络和IP子网的规模。IBTA显然认为RoCE拥有交付大规模、高性能RDMA所需的一切。 </p>
<p>相反，超大规模的玩家和软件定义的网络推广者将这一天带到了“第3层到机架顶部”，导致了机架大小的IP子网，促使IBTA创建了RoCEv2(有时被称为“可路由的RoCE”)。与基于tcp的iWARP不同，RoCEv2运行在UDP之上，它没有慢启动节流行为。转向UDP意味着RoCEv2帧与RoCEv1帧不兼容(尽管支持RoCEv2的rdma支持的NICs通常可以配置为使用RoCEv1格式)。由于UDP缺乏TCP支持IETF的显式拥塞通知(又名ECN, RFCs 3168, 4301, 6040)， IBTA指定RoCEv2也支持IETF的ECN，在UDP之上的IB传输层实现流控制。 </p>
<p>目前的情况是，iWARP和RoCEv2都在争夺基于以太网的NVMe面料市场的所有权 </p>
<p>对其他交通工具的合理批评。 </p>
<p>Non-Volatile Memory Express社区是在2007年英特尔开发者论坛之后兴起的，有兴趣在PCI Express上标准化flash模块的接口。由此产生的NVMe规范更倾向于存储语义而不是内存语义，这主要是因为flash技术面向块的特性。 </p>
<h2 id="NVMe优于SCSI和ATA"><a href="#NVMe优于SCSI和ATA" class="headerlink" title="NVMe优于SCSI和ATA"></a>NVMe优于SCSI和ATA</h2><p>在NVMe开发之前，包括基于闪存的直接连接固态硬盘(ssd)通常通过串行附加SCSI (SAS)或串行ATA进行连接，这两种方式都是并行磁盘接口的序列化版本，最初是在1980年代为dos时代的PC行业定义的。随着操作系统和应用程序的成熟，很少有人注意到这些遗留协议中的复杂性和延迟开销，因为磁盘驱动器的旋转延迟和寻道时间控制了任何磁盘I/O的总体延迟。flash生态系统的成熟改变了这个现状。从一开始，flash就为读取带来了巨大的延迟优势，特别是对于磁盘架构特别薄弱的随机访问读取。写缓存提供了隐藏对flash进行写操作的缓慢速度的能力，但是flash的写耐力挑战和有限的密度限制了它早期对专门领域的适用性。 </p>
<p>随着flash密度的增长和算法的出现，以减轻flash的写擦写数问题，flash逐渐成为一个完全可行的替代旋转磁盘。行业对磁盘友好型SCSI的依赖减弱了，</p>
<p>对高性能SSD协议的开放程度增加了，NVMe就是答案。 </p>
<h2 id="RDMA需要iWARP补丁"><a href="#RDMA需要iWARP补丁" class="headerlink" title="RDMA需要iWARP补丁"></a>RDMA需要iWARP补丁</h2><p>尽管RDMA对于动态共享内存服务器集群应用程序来说是一个强大的协议，但对于存储(尤其是对于小写入)来说，它并不是一个固有的高效协议。假设服务器需要向存储器写入1024字节。RDMA模型是让服务器向存储设备发送一条消息，说:“嘿，我想把1024字节写入卷。字节位于我的内存中，地址在附件的散集列表中。存储设备接收消息和相关的散集列表，然后转过头来向服务器的内存发出RDMA读请求，然后服务器发送1024字节。 </p>
<p>这种传输方式需要三条消息。为了有助于其性能提升，NVMe社区认识到了这一弱点，并对RDMA原则闭上眼睛，针对NVMe定义了一种数据“封装”机制，用于同一个消息中发送有效负载数据。 </p>
<p>但这种“封装”机制与主流RDMA实现iWARP不兼容，所以iWARP社区立即对此进行了研究，在2014年IETF发布了RFC 7306对其进行描述。 </p>
<h2 id="复杂的协议栈并不理想"><a href="#复杂的协议栈并不理想" class="headerlink" title="复杂的协议栈并不理想"></a>复杂的协议栈并不理想</h2><p>NVMe协议比SCSI协议更高效的一个原因是NVMe的协议栈非常简单。看看不同NVMe结构的协议栈。Fibre Channel, RoCEv2, and iWARP协议栈如下。 </p>
<p><img src="/pics/image-20210418150248531.png" alt="image-20210418150248531"></p>
<p>IP/以太网相对于光纤通道的复杂性既不是随机的，也不是没有必要的。随着时间的推移，协议中有几个关键的差异导致了这种复杂性: </p>
<ul>
<li><p>以太网和IP(和TCP/UDP)实现传输层比光纤通道更独立。以太网/IP网络必须支持的全球范围内的地址分配和路由的挑战，需要多个复杂的层和算法。Fibre Channel是为数据中心规模设计的，这个问题本身很复杂，但比以太网/IP简单多了。 </p>
</li>
<li><p>以太网在网络的早期作为一种最佳的共享介质被开发出来。该协议发展了各种零碎的机制，用于避免环路、泛洪、地址学习等。相比之下，Fibre Channel的开发人员能够从这些早期的经验中获益，从而创建了一种更全面一致的协议。 </p>
</li>
<li><p>以太网和IP已经发展到可以在各种各样的环境中工作，从局域网到人，从校园到小办公室到家庭。即插即用的向后兼容性对于大多数环境中的应用至关重要;这种现实给协议栈带来了令人畏惧的需求。Fibre Channel仍然专注于高级数据中心用例，因此没有被迫戏剧性地演进，这大大简化了兼容性问题。 </p>
</li>
</ul>
<p>在此适当地承认，iWARP和RoCEv2堆栈的复杂性并不一定会增加明显的延迟; </p>
<p>栈的大部分复杂性是由专门的RDMA enabled NICs或TCP Offload引擎在“硬件”中处理的。但是复杂的栈转换成配置、管理、互操作性、故障排除和分析方面的挑战。 </p>
<h2 id="关于NVMe-oF-InfiniBand"><a href="#关于NVMe-oF-InfiniBand" class="headerlink" title="关于NVMe-oF (InfiniBand)"></a>关于NVMe-oF (InfiniBand)</h2><p>NVMe已成为PCIe ssd的行业标准接口，具有简化的协议和命令集，每个I/O的时钟周期更少。NVMe支持最多64K队列和每个队列最多64K命令，这使得它比现有的基于scsi的协议(如SAS和SATA)更高效。 </p>
<p>NVMe-oF的引入使其更具有可伸缩性，同时仍然得益于低延迟和小开销。NVMexpress.org规范概述了对nvme的支持——NVMe-oF over Ethernet、远程直接内存访问(RDMA)和光纤通道(FC)。 </p>
<p><img src="/pics/image-20210418150744705.png" alt="image-20210418150744705"></p>
<p>相比SCSI, NVMe(NVMe-oF)可以支持更低的延迟I / O，不仅是因为设备速度更快,还因为一些固有的优势在Linux主机操作系统驱动程序栈(如上图)。因此,I / O花费更少的总时间从应用程序的存储,从而减少响应时间。 </p>
<p>市场上的大多数产品的实现是将NVMe驱动器添加到后端存储，前端保持SCSI主机连接，但NetApp E-Series采取了一种单独的方法。从主机到EF570/E5700的前端采用NVMe-oF(InfiniBand)网络，而后端仍然是基于SCSI的SAS驱动器。 </p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Store/" rel="tag"># Store</a>
              <a href="/tags/NVMe/" rel="tag"># NVMe</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/10/20/store/NVMe/%E5%8D%81%E5%9B%9B%E3%80%81NVMe%20over%20Fabric%E5%B0%86%E5%A6%82%E4%BD%95%E6%94%B9%E5%8F%98%E5%AD%98%E5%82%A8%E7%8E%AF%E5%A2%83%EF%BC%9F/" rel="prev" title="十四、NVMe over Fabric将如何改变存储环境？">
      <i class="fa fa-chevron-left"></i> 十四、NVMe over Fabric将如何改变存储环境？
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/10/22/store/NVMe/%E5%8D%81%E5%85%AD%E3%80%81%E5%85%B3%E4%BA%8ENVMe%E5%92%8CNVMeoF%E7%9F%A5%E8%AF%86%E8%A1%A5%E5%85%85/" rel="next" title="十六、关于NVMe和NVMeoF知识补充">
      十六、关于NVMe和NVMeoF知识补充 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#FC-NVMe如何工作"><span class="nav-text">FC NVMe如何工作</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#FC-NVMe的优点和缺点"><span class="nav-text">FC-NVMe的优点和缺点</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#FC不但可以作为NVMe的Fabrics且更有优势"><span class="nav-text">FC不但可以作为NVMe的Fabrics且更有优势</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RDMA也不是NVMe-Fabric的关键"><span class="nav-text">RDMA也不是NVMe Fabric的关键</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SCSI也不是唯一的FC-Native协议"><span class="nav-text">SCSI也不是唯一的FC Native协议</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#如何看待SCSI到NVMe转换层对NVMe产生的影响？"><span class="nav-text">如何看待SCSI到NVMe转换层对NVMe产生的影响？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#FC能否实现零拷贝-Zero-Copy-功能？"><span class="nav-text">FC能否实现零拷贝(Zero Copy)功能？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#IP上的零拷贝-Zero-Copy-也不需要RDMA"><span class="nav-text">IP上的零拷贝(Zero-Copy)也不需要RDMA</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#可路由的RoCE-v2才是更好的RoCE"><span class="nav-text">可路由的RoCE v2才是更好的RoCE</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#网络化的RDMA经历了一个艰难的阶段"><span class="nav-text">网络化的RDMA经历了一个艰难的阶段</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#NVMe优于SCSI和ATA"><span class="nav-text">NVMe优于SCSI和ATA</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RDMA需要iWARP补丁"><span class="nav-text">RDMA需要iWARP补丁</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#复杂的协议栈并不理想"><span class="nav-text">复杂的协议栈并不理想</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#关于NVMe-oF-InfiniBand"><span class="nav-text">关于NVMe-oF (InfiniBand)</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="摘星"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">摘星</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">261</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">25</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">142</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/zhangkexuan" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zhangkexuan" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="/kexuan_zhang@qq.com" title="E-Mail → kexuan_zhang@qq.com"><i class="fa fa-envelope fa-fw"></i></a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2019 – 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">摘星</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

</body>
</html>

<!-- ҳ����С���� -->
<script type="text/javascript" src="/js/clicklove.js"></script>
